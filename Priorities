4/2/14
1) Get familiar with LeapMotion. We probably should use the Pointable and Gesture classes in the API. "Tapping" should shoot, as the controller seems to have a hard time recognizing both thumb and index finger at the same time. Index finger is a pointable object, so we should use the Vector class to get the vector that extends from it. We will need to import that into Unity whenever a tap is registered.

2) Vectors seem to have a fairly significant vertical limitation-- they can't point up more than about thirty degrees from horizontal. This could potentially be solved by placing the controller on a slope and diagonal to the hand. To do this, however, we need to look into re-orienting the controller. Look into this.

3) When we have the above problems solved, we can begin working with the Oculus in Unity and adding some things to point at.

4/3/14
1.1) Look at UnitySandbox example in SDK. It does a lot of what we need, and we should probably be trying to modify it. Specifically, start with LeapUnitySelectionController class. (C:\Users\jmb113\Downloads\LeapDeveloperKit_release_win_1.0.9+8391\LeapDeveloperKit\Examples\UnitySandbox)
Changing (even completely deleting) this class doesn't seem to affect the way the demo runs. Why?

4/6/14:
meow: copy of UnitySandbox example
meowver1: checkShouldTransform, checkShouldRotate, and checkShouldScale all set to false to remove object manipulation
meowver2: GUI file changed to remove enabling/disabling of manipulation text

4/7/14:
meowver3: change LeapUnityBridge to only recognize one finger
meowver4: look at LeapFingerCollisionDispatcher; try changing KHitDistance and Debug.DrawRay to make ray distance infinite and display it as such. Alternately, try changing updatePointable in LeapUnityHandController. Also, add ScreenTapGesture to trigger collision detection (see https://developer.leapmotion.com/documentation/python/api/Leap.ScreenTapGesture.html).

4/11/14:
meowver4: collision detection along ray from finger is working. Dave helped me add a cube object with tiny width and depth and long length that basically looks like a ray, and we have it set up so that when a ray drawn from the fingertip intersects with any object other than that cube (ourRay), ourRay changes colors to reflect a collision. It's important that ourRay not have a collision detector, otherwise it will overlap with the ray drawn from the fingertip, and it will change colors unexpectedly.
meowver5: TODO: change cube behavior so that it changes to green whenever ourRay does.
meowver6: TODO: add ScreenTapGesture. Collision detection should only take place during gesture.

4/12/14:
meowver5: Cube is highlighted when it intersects with ray. Previously, only the ray was highlighted; cube remained same color unless touched by finger. Changes made to Raycast section of LeapFingerCollisionDispatcher. TODO: remove highlighting when finger touches.
meowver6: Massive changes. Added recognition for screen tap gestures in LeapInput. Added function to return GestureList in LeapUnitySelectionController, and every time a screentap is added to that GestureList, a variable in LeapFingerCollisionDispatcher is set to true. Ray detection from finger only happens when that variable is true; for every frame when no screen tap is detected, it is set to false. Thus, ourRay only appears after "shots," as desired. Color changes still work properly.

4/13/14:
meowver7: Added Oculus Rift support.

4/13/14:
TODO:
1) Add debug mode that draws ourRay all the time
2) Add countdown timer and hit counter to GUI
3) Add highlighting to objects other than cube
4) Try to stop ourRay from moving after first drawn. DONE
5) Try to stop finger touching from highlighting objects
6) If there's still time, try adding other objects downloaded from online

meowver8: Fixed problem of shot ray moving with finger after screen tap by adding rayDrawn variable, changing it to true after detecting a screen tap, and using Invoke() to wait .1 seconds before changing it to false again. Frame history for GestureList for screen taps also had to be decreased from 50 to 5, as when it was 50, it was possible to complete a screen tap that lasted longer than the .1 second wait, which caused unpredictable behavior. .1 seconds was chosen because it allows users to "fire" rapidly but is still long enough to detect a screen tap.


